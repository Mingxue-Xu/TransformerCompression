model-path: 
sliced-model-path: 
cal-dataset: wikitext2
cal-nsamples: 128
cal-batch-size: 16
cal-max-seqlen: 2048
varied-seqlen: 
seed: 42
sparsity: 0.2
round-interval: 8
final-orientation: random
ppl-eval-seqlen: 2048
ppl-eval-batch-size: 1
ppl-eval-nsamples: 128
eval-baseline: 
eval-fused-model: 
ppl-only: 
distribute-model: 
save-dir: data/sliced
hf-token:
wandb-project: slicegpt
no-wandb: True
device: cuda:0
model: meta-llama/Llama-3.2-1B-Instruct
dtype: fp16